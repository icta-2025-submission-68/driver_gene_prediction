{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xujLzXJOvWaa",
        "outputId": "3add7a9d-4f1e-4769-c4dd-85b17e13c026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, gc, warnings, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import average_precision_score, accuracy_score\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEV = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEV)\n",
        "\n",
        "BASE_DIR      = \"/content/drive/My Drive/.....\"\n",
        "EDGE_DIR      = \"/content/drive/MyDrive/.....\"\n",
        "EDGE_TPL      = \"ppi_{c}_plus_knn3_bidirectional.csv\"\n",
        "FEAT_TPL      = \"features_for_{c}.csv\"\n",
        "LABEL_TPL     = \"{c}_labels(0_1).csv\"\n",
        "\n",
        "CANCERS       = [\"BRCA\",\"BLCA\",\"LUAD\",\"LIHC\",\"PRAD\",\"CESC\",\n",
        "                 \"COAD\",\"STAD\",\"THCA\",\"LUSC\",\"UCEC\",\"ESCA\"]\n",
        "\n",
        "SHARED_DIM   = 64\n",
        "HIDDEN_DIM   = 64\n",
        "DROPOUT      = 0.5\n",
        "PT_EPOCHS    = 300\n",
        "FT_EPOCHS    = 200\n",
        "PT_SAVE_DIR  = f\"{BASE_DIR}/pretrain_adapters\"\n",
        "os.makedirs(PT_SAVE_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mMtK73i5DgRz"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "def build_graph(cancer_code: str,\n",
        "                scaler: StandardScaler | None = None) -> Data:\n",
        "    \"\"\"\n",
        "\n",
        "      â€¢ x            : [N, d]\n",
        "      â€¢ edge_index   : [2, E]\n",
        "      â€¢ y            : [-1,0,1]\n",
        "      â€¢ gene_names   : list length N\n",
        "\n",
        "    \"\"\"\n",
        "    edge_path  = os.path.join(EDGE_DIR,  EDGE_TPL.format(c=cancer_code))\n",
        "    feat_path  = os.path.join(BASE_DIR, FEAT_TPL.format(c=cancer_code))\n",
        "    label_path = os.path.join(BASE_DIR, LABEL_TPL.format(c=cancer_code))\n",
        "\n",
        "    edges_df  = pd.read_csv(edge_path)\n",
        "    feat_df   = pd.read_csv(feat_path,  index_col=0).fillna(0)\n",
        "    label_df  = pd.read_csv(label_path)\n",
        "\n",
        "    genes = sorted(set(edges_df['gene1']) | set(edges_df['gene2']))\n",
        "    n2i   = {g: i for i, g in enumerate(genes)}\n",
        "    N     = len(genes)\n",
        "\n",
        "    edge_index = torch.tensor(\n",
        "        [[n2i[a], n2i[b]]\n",
        "         for a, b in edges_df[['gene1', 'gene2']].values\n",
        "         if a in n2i and b in n2i],\n",
        "        dtype=torch.long).T.contiguous()\n",
        "\n",
        "    d       = feat_df.shape[1]\n",
        "    scaler  = scaler or StandardScaler().fit(feat_df.values)\n",
        "    X_scaled = scaler.transform(feat_df.values)\n",
        "    feat_df  = pd.DataFrame(X_scaled, index=feat_df.index)\n",
        "\n",
        "    X        = np.zeros((N, d), dtype=np.float32)\n",
        "    has_feat = np.zeros(N, dtype=bool)\n",
        "\n",
        "    for g, row in feat_df.iterrows():\n",
        "        if g in n2i:\n",
        "            idx = n2i[g]\n",
        "            X[idx]    = row.values\n",
        "            has_feat[idx] = True\n",
        "\n",
        "    neigh = {i: [] for i in range(N)}\n",
        "    for s, d_ in edge_index.T.cpu().numpy():\n",
        "        neigh[s].append(d_)\n",
        "        neigh[d_].append(s)\n",
        "\n",
        "    for i in range(N):\n",
        "        if not has_feat[i]:\n",
        "            neigh_feats = [X[n] for n in neigh[i] if has_feat[n]]\n",
        "            if neigh_feats:\n",
        "                X[i] = np.mean(neigh_feats, axis=0)\n",
        "\n",
        "    y = torch.full((N,), -1, dtype=torch.long)\n",
        "    for _, row in label_df.iterrows():\n",
        "        g, lab = row['Gene'], row['Labels']\n",
        "        if g in n2i:\n",
        "            y[n2i[g]] = int(lab)\n",
        "\n",
        "    data = Data(x=torch.tensor(X), edge_index=edge_index, y=y)\n",
        "    data.gene_names = genes\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K4UWfXv5vjjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccce2975-92a2-4b97-a239-eefb0f80829f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature dimensionality for each cancer type: {'BRCA': 11, 'BLCA': 10, 'LUAD': 11, 'LIHC': 15, 'PRAD': 12, 'CESC': 18, 'COAD': 13, 'STAD': 12, 'THCA': 9, 'LUSC': 11, 'UCEC': 12, 'ESCA': 9}\n"
          ]
        }
      ],
      "source": [
        "graphs, input_dims = {}, {}\n",
        "for c in CANCERS:\n",
        "    graphs[c] = build_graph(c)\n",
        "    input_dims[c] = graphs[c].num_node_features\n",
        "print(\"Feature dimensionality for each cancer type:\", input_dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "huu0IriO_E08"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN_AE(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hid_dim)\n",
        "        self.conv2 = GCNConv(hid_dim, in_dim)\n",
        "    def forward(self, x, edge_index):\n",
        "        h = F.relu(self.conv1(x, edge_index))\n",
        "        x_hat = self.conv2(h, edge_index)\n",
        "        return x_hat\n",
        "\n",
        "class GCN_Classifier_with_MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim=64, mlp_hidden=32, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.gcn1 = GCNConv(in_dim, hid_dim)\n",
        "        self.gcn2 = GCNConv(hid_dim, hid_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hid_dim, mlp_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_hidden, 1)\n",
        "        )\n",
        "    def forward(self, x, edge_index):\n",
        "        h = F.relu(self.gcn1(x, edge_index))\n",
        "        h = F.relu(self.gcn2(h, edge_index))\n",
        "        return self.mlp(h).squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iZFrzhYN_F3m"
      },
      "outputs": [],
      "source": [
        "def stage1_attribute_pretrain(data, hid=64, epoch=200, lr=1e-3, save_path=None):\n",
        "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    data = data.to(dev)\n",
        "    model = GCN_AE(data.num_node_features, hid).to(dev)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    for ep in range(1, epoch+1):\n",
        "        model.train(); opt.zero_grad()\n",
        "        x_hat = model(data.x, data.edge_index)\n",
        "        loss = mse(x_hat, data.x)\n",
        "        loss.backward(); opt.step()\n",
        "        if ep % 20 == 0 or ep == 1:\n",
        "            print(f\"[Stage1] Ep{ep:03d}/{epoch} | MSE {loss.item():.4f}\")\n",
        "    if save_path:\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    return model.state_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bvyJoygJ_JTT"
      },
      "outputs": [],
      "source": [
        "import random, numpy as np\n",
        "from sklearn.metrics import average_precision_score, accuracy_score\n",
        "\n",
        "def stage2_label_pretrain(graphs, target, attr_state_dict,\n",
        "                          hid=64, epochs=300, ckpt_dir=\"./ckpt\"):\n",
        "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    data = graphs[target].to(dev)\n",
        "\n",
        "    pos_genes = {g for c,gx in graphs.items() if c!=target\n",
        "                 for g,l in zip(gx.gene_names, gx.y.tolist()) if l==1}\n",
        "    pos_idx = [i for i,g in enumerate(data.gene_names) if g in pos_genes]\n",
        "    neg_pool= [i for i in range(data.num_nodes) if data.y[i]==-1 and i not in pos_idx]\n",
        "    neg_idx = random.sample(neg_pool, k=len(pos_idx))\n",
        "\n",
        "    print(f\"Stage2: pos {len(pos_idx)} | neg {len(neg_idx)}\")\n",
        "\n",
        "    y_syn = torch.full((data.num_nodes,), -1, dtype=torch.float32, device=dev)\n",
        "    y_syn[pos_idx] = 1.0\n",
        "    y_syn[neg_idx] = 0.0\n",
        "    train_mask = y_syn != -1\n",
        "\n",
        "    model = GCN_Classifier_with_MLP(data.num_node_features, hid).to(dev)\n",
        "    model.gcn1.load_state_dict({k.replace('conv1.', ''): v\n",
        "                            for k,v in attr_state_dict.items()\n",
        "                            if k.startswith('conv1.')})\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); opt.zero_grad()\n",
        "        logit = model(data.x, data.edge_index)\n",
        "        loss  = bce(logit[train_mask], y_syn[train_mask])\n",
        "        loss.backward(); opt.step()\n",
        "\n",
        "        if ep % 20 == 0 or ep in (1,100,200,300):\n",
        "            model.eval();\n",
        "            with torch.no_grad():\n",
        "                p = torch.sigmoid(model(data.x, data.edge_index)[train_mask]).cpu()\n",
        "                au = average_precision_score(y_syn[train_mask].cpu(), p)\n",
        "            print(f\"[Stage2] Ep{ep:03d}/{epochs} | loss {loss.item():.4f} | AUPRC {au:.3f}\")\n",
        "\n",
        "        if ep in (100,200,300):\n",
        "            ck = f\"{ckpt_dir}/pretrain_{target}_ep{ep}.pth\"\n",
        "            torch.save(model.state_dict(), ck)\n",
        "            print(\" saved\", ck)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH2ETaLO_NyK"
      },
      "outputs": [],
      "source": [
        "SAVE_DIR = \"/content/drive/MyDrive/pretrain_Graph\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ---- Stage 1 ----\n",
        "attr_w = stage1_attribute_pretrain(\n",
        "    data       = graphs[\"BLCA\"],\n",
        "    hid        = 64,\n",
        "    epoch      = 200,\n",
        "    lr         = 1e-3,\n",
        "    save_path  = f\"{SAVE_DIR}/attr_BLCA_ep200.pth\"\n",
        ")\n",
        "\n",
        "# ---- Stage 2 ----\n",
        "stage2_label_pretrain(\n",
        "    graphs     = graphs,\n",
        "    target     = \"BLCA\",\n",
        "    attr_state_dict = attr_w,\n",
        "    hid        = 64,\n",
        "    epochs     = 300,\n",
        "    ckpt_dir   = SAVE_DIR\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uEeDhm7xBfTi"
      },
      "outputs": [],
      "source": [
        "import os, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, average_precision_score\n",
        "\n",
        "def finetune_gcn_classifier(\n",
        "        data: Data,\n",
        "        ckpt_path: str,\n",
        "        epochs: int = 200,\n",
        "        lr: float = 1e-3,\n",
        "        freeze_epochs: int = 20,\n",
        "        patience: int = 40,\n",
        "        weight_decay: float = 5e-4,\n",
        "        seed: int = 42,\n",
        "        save_dir: str = None):\n",
        "\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    data   = data.to(device)\n",
        "\n",
        "    labeled_idx = torch.where(data.y != -1)[0]\n",
        "    y_np        = data.y[labeled_idx].cpu().numpy()\n",
        "    skf         = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "    all_metrics = []\n",
        "\n",
        "    for fold, (trval, te) in enumerate(skf.split(np.arange(len(y_np)), y_np), 1):\n",
        "        print(f\"\\n Fold {fold}/5 -------------------------------\")\n",
        "\n",
        "        trval = labeled_idx[trval]; te = labeled_idx[te]\n",
        "        split = int(0.8*len(trval))\n",
        "        tr_idx, va_idx = trval[:split], trval[split:]\n",
        "\n",
        "\n",
        "        def mask(idx):\n",
        "            m = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
        "            m[idx] = True\n",
        "            return m\n",
        "        m_tr, m_va, m_te = map(mask, [tr_idx, va_idx, te])\n",
        "\n",
        "        model = GCN_Classifier_with_MLP(in_dim=data.num_node_features, hid_dim=64).to(device)\n",
        "\n",
        "        model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=True)\n",
        "        print(f\" Loaded checkpoint {ckpt_path}\")\n",
        "\n",
        "\n",
        "        if freeze_epochs > 0:\n",
        "            for p in model.gcn1.parameters(): p.requires_grad_(False)\n",
        "            print(f\"  Freeze encoder {freeze_epochs} epoch Ä‘áº§u\")\n",
        "\n",
        "        opt = torch.optim.Adam(filter(lambda p:p.requires_grad, model.parameters()),\n",
        "                               lr=lr, weight_decay=weight_decay)\n",
        "        loss_fn = nn.BCEWithLogitsLoss(\n",
        "            pos_weight=torch.tensor(float((data.y[m_tr]==0).sum() /\n",
        "                                          max(1, (data.y[m_tr]==1).sum())),\n",
        "                                    device=device))\n",
        "\n",
        "        best_state, best_val, wait = None, 1e9, 0\n",
        "        for ep in range(1, epochs+1):\n",
        "\n",
        "\n",
        "            if ep == freeze_epochs+1:\n",
        "                for p in model.gcn1.parameters(): p.requires_grad_(True)\n",
        "                opt = torch.optim.Adam(model.parameters(), lr=lr/10, weight_decay=weight_decay)\n",
        "                print(\"  Unfreeze encoder\")\n",
        "\n",
        "\n",
        "            model.train(); opt.zero_grad()\n",
        "            logit = model(data.x, data.edge_index)\n",
        "            loss  = loss_fn(logit[m_tr], data.y[m_tr].float())\n",
        "            loss.backward(); opt.step()\n",
        "\n",
        "\n",
        "            model.eval();\n",
        "            with torch.no_grad():\n",
        "                logit_va = model(data.x, data.edge_index)[m_va]\n",
        "                val_loss = loss_fn(logit_va, data.y[m_va].float()).item()\n",
        "\n",
        "\n",
        "            if val_loss < best_val:\n",
        "                best_val, best_state, wait = val_loss, model.state_dict(), 0\n",
        "            else:\n",
        "                wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"  Early-stop táº¡i epoch {ep}\")\n",
        "                break\n",
        "\n",
        "            if ep % 20 == 0 or ep == 1:\n",
        "                with torch.no_grad():\n",
        "                    probs_va = torch.sigmoid(logit_va).cpu()\n",
        "                    au_va = average_precision_score(data.y[m_va].cpu(), probs_va)\n",
        "                    print(f\"Ep{ep:03d} | TrainL {loss.item():.4f} | ValL {val_loss:.4f} | ValAUPRC {au_va:.3f}\")\n",
        "\n",
        "\n",
        "        model.load_state_dict(best_state)\n",
        "        model.eval();\n",
        "        with torch.no_grad():\n",
        "            probs_te = torch.sigmoid(model(data.x, data.edge_index)[m_te]).cpu()\n",
        "            acc_te   = accuracy_score(data.y[m_te].cpu(), (probs_te>0.5).long())\n",
        "            au_te    = average_precision_score(data.y[m_te].cpu(), probs_te)\n",
        "            print(f\"âœ… Fold {fold} TEST | Acc {acc_te:.3f} | AUPRC {au_te:.3f}\")\n",
        "            all_metrics.append((acc_te, au_te))\n",
        "\n",
        "        if save_dir:\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            torch.save(best_state, f\"{save_dir}/best_fold{fold}.pth\")\n",
        "\n",
        "    accs, auprs = zip(*all_metrics)\n",
        "    print(f\"\\nðŸ“Š 5-fold summary â‡’  Acc {np.mean(accs):.3f} Â± {np.std(accs):.3f} | \"\n",
        "          f\"AUPRC {np.mean(auprs):.3f} Â± {np.std(auprs):.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOyCe71_BkYU"
      },
      "outputs": [],
      "source": [
        "CKPT_STAGE2 = \"/content/drive/MyDrive/pretrain_Graph/pretrain_BLCA_ep300.pth\"\n",
        "DATA_cancer   = graphs[\"BLCA\"]\n",
        "\n",
        "finetune_gcn_classifier(\n",
        "    data          = DATA_cancer,\n",
        "    ckpt_path     = CKPT_STAGE2,\n",
        "    epochs        = 300,\n",
        "    freeze_epochs = 20,\n",
        "    patience      = 40,\n",
        "    lr            = 1e-3,\n",
        "    save_dir      = \"/content/drive/MyDrive/BLCA_all_finetune_graph\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}