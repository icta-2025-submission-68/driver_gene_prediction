{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVs4j8jUr4Cg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "\n",
        "\n",
        "c = 'BRCA'\n",
        "edges_df = pd.read_csv('/content/drive/My Drive/networks/ppi_{c}_plus_knn3_bidirectional.csv')\n",
        "features_df = pd.read_csv('/content/drive/My Drive/features/features_for_{c}.csv', index_col=0)\n",
        "labels_df = pd.read_csv('/content/drive/My Drive/lables/{c}_labels(0_1).csv')\n",
        "\n",
        "\n",
        "genes_from_edges = set(edges_df['gene1']).union(set(edges_df['gene2']))\n",
        "genes_from_features = set(features_df.index)\n",
        "all_genes = sorted(genes_from_edges)\n",
        "\n",
        "node_to_idx = {gene: i for i, gene in enumerate(all_genes)}\n",
        "idx_to_node = {i: gene for gene, i in node_to_idx.items()}\n",
        "\n",
        "edges = edges_df[['gene1', 'gene2']].dropna()\n",
        "edge_index = torch.tensor([[node_to_idx[a], node_to_idx[b]]\n",
        "                           for a, b in edges.values if a in node_to_idx and b in node_to_idx],\n",
        "                          dtype=torch.long).t().contiguous()\n",
        "\n",
        "feature_dim = features_df.shape[1]\n",
        "x_matrix = np.zeros((len(all_genes), feature_dim))\n",
        "has_feature = np.zeros(len(all_genes), dtype=bool)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_df.values)\n",
        "features_scaled_df = pd.DataFrame(features_scaled, index=features_df.index)\n",
        "\n",
        "for gene in features_scaled_df.index:\n",
        "    if gene in node_to_idx:\n",
        "        idx = node_to_idx[gene]\n",
        "        x_matrix[idx] = features_scaled_df.loc[gene].values\n",
        "        has_feature[idx] = True\n",
        "\n",
        "neighbors_dict = {i: [] for i in range(len(all_genes))}\n",
        "for src, dst in edge_index.t().tolist():\n",
        "    neighbors_dict[src].append(dst)\n",
        "    neighbors_dict[dst].append(src)\n",
        "\n",
        "for i in range(len(all_genes)):\n",
        "    if not has_feature[i]:\n",
        "        neighbor_feats = [x_matrix[n] for n in neighbors_dict[i] if has_feature[n]]\n",
        "        if neighbor_feats:\n",
        "            x_matrix[i] = np.mean(neighbor_feats, axis=0)\n",
        "\n",
        "\n",
        "x = torch.tensor(x_matrix, dtype=torch.float)\n",
        "\n",
        "labels_map = {row['Gene']: row['Labels'] for _, row in labels_df.iterrows()}\n",
        "y = torch.full((x.size(0),), -1, dtype=torch.long)\n",
        "\n",
        "for gene, label in labels_map.items():\n",
        "    if gene in node_to_idx:\n",
        "        y[node_to_idx[gene]] = int(label)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "class GCN1(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, dropout=0.5):\n",
        "        super(GCN1, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, 1)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index).squeeze()\n",
        "        return x\n",
        "\n",
        "def train(model, data, mask, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(data.x, data.edge_index)\n",
        "    labels = data.y[mask].float()\n",
        "    loss = loss_fn(logits[mask], labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(model, data, mask, loss_fn):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        logits_masked = logits[mask]\n",
        "        labels = data.y[mask].float()\n",
        "\n",
        "        loss = loss_fn(logits_masked, labels).item()\n",
        "\n",
        "        probs = torch.sigmoid(logits_masked).cpu()\n",
        "        labels_cpu = labels.cpu()\n",
        "        preds = (probs > 0.5).long()\n",
        "        acc = accuracy_score(labels_cpu, preds)\n",
        "        auprc = average_precision_score(labels_cpu, probs)\n",
        "        return acc, auprc, loss\n",
        "\n",
        "def train_model_5fold(data, hidden_channels=64,\n",
        "                       epochs=200, patience=30, min_delta=1e-4):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    data = data.to(device)\n",
        "\n",
        "    labeled_idx = torch.where(data.y != -1)[0]\n",
        "    labeled_y   = data.y[labeled_idx].cpu().numpy()\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=46)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_val_idx, test_idx) in enumerate(skf.split(np.arange(len(labeled_y)), labeled_y)):\n",
        "        print(f\"\\nüìÇ Fold {fold+1}/5\")\n",
        "\n",
        "        train_val_idx = labeled_idx[train_val_idx]\n",
        "        test_idx      = labeled_idx[test_idx]\n",
        "\n",
        "        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=44)\n",
        "        train_nodes, val_nodes = next(\n",
        "            sss.split(np.zeros(len(train_val_idx)), data.y[train_val_idx].cpu().numpy())\n",
        "        )\n",
        "        train_nodes = train_val_idx[train_nodes]\n",
        "        val_nodes   = train_val_idx[val_nodes]\n",
        "        test_nodes  = test_idx\n",
        "\n",
        "        n_total   = data.num_nodes\n",
        "        train_mask = torch.zeros(n_total, dtype=torch.bool, device=device)\n",
        "        val_mask   = torch.zeros_like(train_mask)\n",
        "        test_mask  = torch.zeros_like(train_mask)\n",
        "        train_mask[train_nodes] = True\n",
        "        val_mask  [val_nodes]   = True\n",
        "        test_mask [test_nodes]  = True\n",
        "\n",
        "        pos_weight_value  = (data.y[train_nodes] == 0).sum() / (data.y[train_nodes] == 1).sum()\n",
        "        pos_weight_tensor = torch.tensor(float(pos_weight_value), dtype=torch.float32, device=device)\n",
        "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
        "\n",
        "        model = GCN1(data.num_node_features, hidden_channels).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "        best_val = 0.0\n",
        "        best_state = None\n",
        "        wait = 0\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train_loss = train(model, data, train_mask, optimizer, loss_fn)\n",
        "            train_acc, train_auprc, _  = evaluate(model, data, train_mask, loss_fn)\n",
        "            val_acc,   val_auprc, vls  = evaluate(model, data, val_mask, loss_fn)\n",
        "\n",
        "            print(f\"Ep{epoch:03d} | \"\n",
        "                  f\"Train Acc {train_acc:.4f}, AUPRC {train_auprc:.4f} | \"\n",
        "                  f\"Val Acc {val_acc:.4f}, AUPRC {val_auprc:.4f}, Loss {vls:.4f}\")\n",
        "\n",
        "\n",
        "            if val_auprc - best_val > min_delta:\n",
        "                best_val  = val_auprc\n",
        "                best_state = model.state_dict()\n",
        "                wait = 0\n",
        "            else:\n",
        "                wait += 1\n",
        "                if wait >= patience:\n",
        "                    print(f\"‚èπÔ∏è  Stop early at epoch {epoch} (no impro ‚â•{patience})\")\n",
        "                    break\n",
        "\n",
        "\n",
        "        if best_state is not None:\n",
        "            model.load_state_dict(best_state)\n",
        "\n",
        "        test_acc, test_auprc, _ = evaluate(model, data, test_mask, loss_fn)\n",
        "        print(f\"‚úÖ Test Accuracy: {test_acc:.4f} | AUPRC: {test_auprc:.4f}\")\n",
        "        results.append((test_acc, test_auprc))\n",
        "    if results:\n",
        "        accs, auprcs = map(np.array, zip(*results))\n",
        "        print(\"\\nüìä 5 fold:\")\n",
        "        print(f\"  Accuracy: {accs.mean():.4f} ¬± {accs.std():.4f}\")\n",
        "        print(f\"  AUPRC:    {auprcs.mean():.4f} ¬± {auprcs.std():.4f}\")\n",
        "train_model_5fold(data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}